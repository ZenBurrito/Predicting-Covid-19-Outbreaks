{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZenBurrito/Predicting-Covid-19-Outbreaks/blob/test/Copy_of_Pre_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YHngHcS9a0Bc"
      },
      "outputs": [],
      "source": [
        "#Data\n",
        "import requests\n",
        "import csv\n",
        "\n",
        "#EDA and Visualizations\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "#modeling\n",
        "from nltk.tokenize import TweetTokenizer, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score, confusion_matrix, mean_squared_error, roc_curve, auc, roc_auc_score\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "import psutil\n",
        "\n",
        "import datetime\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Business Understanding\n",
        "\n",
        "Data used in this project came from Kaggle, the CDC, Google Trends, and Twitter. Using basic NLP libraries (NLTK, TweetTokenizer)\n",
        "\n",
        "For the analysis of the tweets I started with a basic, mostly cleaned, dataset off of Kaggle to create text based predictors. I also gathered my own twitter data about vaccinations, which accounted for another 10000 rows. I used other libraries to clean the text (TextHero), and then used a Trigram CountVectorizer. To create my target variable I used data from Google Trends and the CDC. Using percentages of new cases and trending relevance, I created a score between the two that accounts for not only physical outbreaks, but a social one as well.\n",
        "\n",
        "\n",
        "\n",
        "Covid-19 is a problem that does not need much introduction or explanantion, however, for this project I wanted to find if there was any correlation between twitter behavior and possible outbreaks. This is important to understand because this could help hospitals better prepare for a response to an outbreak. This could also be applicable to anybody wanting to avoid close contact with the disease, giving them warning beforehand, which they can then use to make more informed decisions on how to handle their day to day."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Preprocessing and Understanding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ir9A43poUdbB"
      },
      "source": [
        "### Google Trends Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GSYPFJxTa0Bd",
        "outputId": "ccbaa9df-16ba-4cb4-c62a-2864770ed8d5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category: All categories</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Week</th>\n",
              "      <td>Symptoms of COVID-19: (United States)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-03</th>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-10</th>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-17</th>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-05-24</th>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-12-12</th>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-12-19</th>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-12-26</th>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-02</th>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-09</th>\n",
              "      <td>73</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                         Category: All categories\n",
              "Week        Symptoms of COVID-19: (United States)\n",
              "2020-05-03                                     35\n",
              "2020-05-10                                     34\n",
              "2020-05-17                                     32\n",
              "2020-05-24                                     30\n",
              "...                                           ...\n",
              "2021-12-12                                     34\n",
              "2021-12-19                                     56\n",
              "2021-12-26                                     78\n",
              "2022-01-02                                     81\n",
              "2022-01-09                                     73\n",
              "\n",
              "[90 rows x 1 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "google = pd.read_csv('data/covid_searches.csv')\n",
        "google"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3y_Xv5MKyq_",
        "outputId": "35026608-85bb-4aa0-e610-0f34c2a0128a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 90 entries, 0 to 89\n",
            "Data columns (total 2 columns):\n",
            " #   Column                    Non-Null Count  Dtype \n",
            "---  ------                    --------------  ----- \n",
            " 0   index                     90 non-null     object\n",
            " 1   Category: All categories  90 non-null     object\n",
            "dtypes: object(2)\n",
            "memory usage: 1.5+ KB\n"
          ]
        }
      ],
      "source": [
        "google.reset_index(inplace=True)\n",
        "\n",
        "google.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "h8DZ62QAKytp"
      },
      "outputs": [],
      "source": [
        "google.drop(index=google.index[0], \n",
        "        axis=0, \n",
        "        inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wphJGeq_KyvU",
        "outputId": "446eb6e3-ed5c-4c16-994d-fea7c60ae763"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-05-03</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-05-10</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-05-17</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-05-24</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2020-05-31</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>2021-12-12</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>2021-12-19</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>2021-12-26</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>2022-01-02</td>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>2022-01-09</td>\n",
              "      <td>73</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>89 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          date relevance\n",
              "1   2020-05-03        35\n",
              "2   2020-05-10        34\n",
              "3   2020-05-17        32\n",
              "4   2020-05-24        30\n",
              "5   2020-05-31        27\n",
              "..         ...       ...\n",
              "85  2021-12-12        34\n",
              "86  2021-12-19        56\n",
              "87  2021-12-26        78\n",
              "88  2022-01-02        81\n",
              "89  2022-01-09        73\n",
              "\n",
              "[89 rows x 2 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "google['date'] = google['index']\n",
        "google['relevance'] = google['Category: All categories']\n",
        "\n",
        "google.drop(columns='index', inplace=True)\n",
        "google.drop(columns='Category: All categories', inplace=True)\n",
        "\n",
        "google"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_sZ3cfL_avR6"
      },
      "outputs": [],
      "source": [
        "google['date'] = pd.to_datetime(google['date'])\n",
        "\n",
        "google['relevance'] = google['relevance'].astype(int)\n",
        "\n",
        "google['outbreak'] = [x for x in google['relevance'] > 50]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZX2rpTgka0Be"
      },
      "source": [
        "### CDC Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "w9M3MzBYa0Bf",
        "outputId": "44cce2b1-8da5-4454-d5e2-660687be95cd",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>submission_date</th>\n",
              "      <th>state</th>\n",
              "      <th>tot_cases</th>\n",
              "      <th>conf_cases</th>\n",
              "      <th>prob_cases</th>\n",
              "      <th>new_case</th>\n",
              "      <th>pnew_case</th>\n",
              "      <th>tot_death</th>\n",
              "      <th>conf_death</th>\n",
              "      <th>prob_death</th>\n",
              "      <th>new_death</th>\n",
              "      <th>pnew_death</th>\n",
              "      <th>created_at</th>\n",
              "      <th>consent_cases</th>\n",
              "      <th>consent_deaths</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>03/11/2021</td>\n",
              "      <td>KS</td>\n",
              "      <td>297229</td>\n",
              "      <td>241035.0</td>\n",
              "      <td>56194.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4851</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>03/12/2021 03:20:13 PM</td>\n",
              "      <td>Agree</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>06/11/2021</td>\n",
              "      <td>TX</td>\n",
              "      <td>2965966</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1463</td>\n",
              "      <td>355.0</td>\n",
              "      <td>51158</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17</td>\n",
              "      <td>0.0</td>\n",
              "      <td>06/13/2021 12:00:00 AM</td>\n",
              "      <td>Not agree</td>\n",
              "      <td>Not agree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>01/02/2022</td>\n",
              "      <td>AS</td>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>01/03/2022 03:18:16 PM</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>08/22/2020</td>\n",
              "      <td>AR</td>\n",
              "      <td>56199</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>547</td>\n",
              "      <td>0.0</td>\n",
              "      <td>674</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11</td>\n",
              "      <td>0.0</td>\n",
              "      <td>08/23/2020 02:15:28 PM</td>\n",
              "      <td>Not agree</td>\n",
              "      <td>Not agree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>07/17/2020</td>\n",
              "      <td>MP</td>\n",
              "      <td>37</td>\n",
              "      <td>37.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>07/19/2020 12:00:00 AM</td>\n",
              "      <td>Agree</td>\n",
              "      <td>Agree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43135</th>\n",
              "      <td>05/28/2020</td>\n",
              "      <td>IA</td>\n",
              "      <td>18585</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>228</td>\n",
              "      <td>0.0</td>\n",
              "      <td>506</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>05/29/2020 02:19:55 PM</td>\n",
              "      <td>Not agree</td>\n",
              "      <td>Not agree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43136</th>\n",
              "      <td>06/07/2020</td>\n",
              "      <td>SD</td>\n",
              "      <td>5438</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>65</td>\n",
              "      <td>64.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>06/08/2020 02:55:08 PM</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Agree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43137</th>\n",
              "      <td>04/30/2021</td>\n",
              "      <td>SD</td>\n",
              "      <td>122660</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>128</td>\n",
              "      <td>17.0</td>\n",
              "      <td>1967</td>\n",
              "      <td>1601.0</td>\n",
              "      <td>366.0</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>05/01/2021 01:43:22 PM</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Agree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43138</th>\n",
              "      <td>03/10/2021</td>\n",
              "      <td>SD</td>\n",
              "      <td>113962</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>209</td>\n",
              "      <td>37.0</td>\n",
              "      <td>1904</td>\n",
              "      <td>1546.0</td>\n",
              "      <td>358.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>03/11/2021 03:36:21 PM</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Agree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43139</th>\n",
              "      <td>05/27/2021</td>\n",
              "      <td>OH</td>\n",
              "      <td>1100312</td>\n",
              "      <td>921199.0</td>\n",
              "      <td>179113.0</td>\n",
              "      <td>732</td>\n",
              "      <td>196.0</td>\n",
              "      <td>19753</td>\n",
              "      <td>19753.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>05/28/2021 01:29:21 PM</td>\n",
              "      <td>Agree</td>\n",
              "      <td>Agree</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>43140 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      submission_date state  tot_cases  conf_cases  prob_cases  new_case  \\\n",
              "0          03/11/2021    KS     297229    241035.0     56194.0         0   \n",
              "1          06/11/2021    TX    2965966         NaN         NaN      1463   \n",
              "2          01/02/2022    AS         11         NaN         NaN         0   \n",
              "3          08/22/2020    AR      56199         NaN         NaN       547   \n",
              "4          07/17/2020    MP         37        37.0         0.0         1   \n",
              "...               ...   ...        ...         ...         ...       ...   \n",
              "43135      05/28/2020    IA      18585         NaN         NaN       228   \n",
              "43136      06/07/2020    SD       5438         NaN         NaN        71   \n",
              "43137      04/30/2021    SD     122660         NaN         NaN       128   \n",
              "43138      03/10/2021    SD     113962         NaN         NaN       209   \n",
              "43139      05/27/2021    OH    1100312    921199.0    179113.0       732   \n",
              "\n",
              "       pnew_case  tot_death  conf_death  prob_death  new_death  pnew_death  \\\n",
              "0            0.0       4851         NaN         NaN          0         0.0   \n",
              "1          355.0      51158         NaN         NaN         17         0.0   \n",
              "2            0.0          0         NaN         NaN          0         0.0   \n",
              "3            0.0        674         NaN         NaN         11         0.0   \n",
              "4            0.0          2         2.0         0.0          0         0.0   \n",
              "...          ...        ...         ...         ...        ...         ...   \n",
              "43135        0.0        506         NaN         NaN         14         0.0   \n",
              "43136        0.0         65        64.0         1.0          0         1.0   \n",
              "43137       17.0       1967      1601.0       366.0          5         1.0   \n",
              "43138       37.0       1904      1546.0       358.0          3         0.0   \n",
              "43139      196.0      19753     19753.0         0.0          0         0.0   \n",
              "\n",
              "                   created_at consent_cases consent_deaths  \n",
              "0      03/12/2021 03:20:13 PM         Agree            NaN  \n",
              "1      06/13/2021 12:00:00 AM     Not agree      Not agree  \n",
              "2      01/03/2022 03:18:16 PM           NaN            NaN  \n",
              "3      08/23/2020 02:15:28 PM     Not agree      Not agree  \n",
              "4      07/19/2020 12:00:00 AM         Agree          Agree  \n",
              "...                       ...           ...            ...  \n",
              "43135  05/29/2020 02:19:55 PM     Not agree      Not agree  \n",
              "43136  06/08/2020 02:55:08 PM           NaN          Agree  \n",
              "43137  05/01/2021 01:43:22 PM           NaN          Agree  \n",
              "43138  03/11/2021 03:36:21 PM           NaN          Agree  \n",
              "43139  05/28/2021 01:29:21 PM         Agree          Agree  \n",
              "\n",
              "[43140 rows x 15 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "CDC = pd.read_csv('data/USA_covid_stats.csv')\n",
        "CDC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Y02HvAAgMyN4"
      },
      "outputs": [],
      "source": [
        "CDC['date'] = CDC['submission_date']\n",
        "\n",
        "CDC.drop(columns='submission_date', axis=0, inplace=True)\n",
        "\n",
        "\n",
        "col = ['state', 'conf_cases', 'prob_cases', 'pnew_case', 'conf_death', 'prob_death', 'pnew_death', 'created_at', 'consent_cases', 'consent_deaths']\n",
        "\n",
        "CDC.drop(columns=col, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3shqTY8AT5h8"
      },
      "outputs": [],
      "source": [
        "CDC.dropna(how='all', inplace=True)\n",
        "\n",
        "CDC['date'] = pd.to_datetime(CDC['date']).dt.normalize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_TdNF85-a0Bg",
        "outputId": "b822531a-6d28-4c3b-e5e5-a8ed317c16ff",
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tot_cases</th>\n",
              "      <th>new_case</th>\n",
              "      <th>tot_death</th>\n",
              "      <th>new_death</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>297229</td>\n",
              "      <td>0</td>\n",
              "      <td>4851</td>\n",
              "      <td>0</td>\n",
              "      <td>2021-03-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2965966</td>\n",
              "      <td>1463</td>\n",
              "      <td>51158</td>\n",
              "      <td>17</td>\n",
              "      <td>2021-06-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2022-01-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56199</td>\n",
              "      <td>547</td>\n",
              "      <td>674</td>\n",
              "      <td>11</td>\n",
              "      <td>2020-08-22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2020-07-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43135</th>\n",
              "      <td>18585</td>\n",
              "      <td>228</td>\n",
              "      <td>506</td>\n",
              "      <td>14</td>\n",
              "      <td>2020-05-28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43136</th>\n",
              "      <td>5438</td>\n",
              "      <td>71</td>\n",
              "      <td>65</td>\n",
              "      <td>0</td>\n",
              "      <td>2020-06-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43137</th>\n",
              "      <td>122660</td>\n",
              "      <td>128</td>\n",
              "      <td>1967</td>\n",
              "      <td>5</td>\n",
              "      <td>2021-04-30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43138</th>\n",
              "      <td>113962</td>\n",
              "      <td>209</td>\n",
              "      <td>1904</td>\n",
              "      <td>3</td>\n",
              "      <td>2021-03-10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43139</th>\n",
              "      <td>1100312</td>\n",
              "      <td>732</td>\n",
              "      <td>19753</td>\n",
              "      <td>0</td>\n",
              "      <td>2021-05-27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>43140 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       tot_cases  new_case  tot_death  new_death       date\n",
              "0         297229         0       4851          0 2021-03-11\n",
              "1        2965966      1463      51158         17 2021-06-11\n",
              "2             11         0          0          0 2022-01-02\n",
              "3          56199       547        674         11 2020-08-22\n",
              "4             37         1          2          0 2020-07-17\n",
              "...          ...       ...        ...        ...        ...\n",
              "43135      18585       228        506         14 2020-05-28\n",
              "43136       5438        71         65          0 2020-06-07\n",
              "43137     122660       128       1967          5 2021-04-30\n",
              "43138     113962       209       1904          3 2021-03-10\n",
              "43139    1100312       732      19753          0 2021-05-27\n",
              "\n",
              "[43140 rows x 5 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "CDC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV3-1UKAa0Bg"
      },
      "source": [
        "### Twitter Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "yiuRm5kva0Bh",
        "outputId": "31887269-1cc2-4589-c109-b6f29b2474c5",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-950cf813-1af8-4078-92ce-c36b9cb009ef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_name</th>\n",
              "      <th>user_location</th>\n",
              "      <th>user_description</th>\n",
              "      <th>user_created</th>\n",
              "      <th>user_followers</th>\n",
              "      <th>user_friends</th>\n",
              "      <th>user_favourites</th>\n",
              "      <th>user_verified</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>source</th>\n",
              "      <th>is_retweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ᏉᎥ☻լꂅϮ</td>\n",
              "      <td>astroworld</td>\n",
              "      <td>wednesday addams as a disney princess keepin i...</td>\n",
              "      <td>2017-05-26 05:46:42</td>\n",
              "      <td>624</td>\n",
              "      <td>950</td>\n",
              "      <td>18775</td>\n",
              "      <td>False</td>\n",
              "      <td>2020-07-25 12:27:21</td>\n",
              "      <td>If I smelled the scent of hand sanitizers toda...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tom Basile 🇺🇸</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>Husband, Father, Columnist &amp; Commentator. Auth...</td>\n",
              "      <td>2009-04-16 20:06:23</td>\n",
              "      <td>2253</td>\n",
              "      <td>1677</td>\n",
              "      <td>24</td>\n",
              "      <td>True</td>\n",
              "      <td>2020-07-25 12:27:17</td>\n",
              "      <td>Hey @Yankees @YankeesPR and @MLB - wouldn't it...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Time4fisticuffs</td>\n",
              "      <td>Pewee Valley, KY</td>\n",
              "      <td>#Christian #Catholic #Conservative #Reagan #Re...</td>\n",
              "      <td>2009-02-28 18:57:41</td>\n",
              "      <td>9275</td>\n",
              "      <td>9525</td>\n",
              "      <td>7254</td>\n",
              "      <td>False</td>\n",
              "      <td>2020-07-25 12:27:14</td>\n",
              "      <td>@diane3443 @wdunlap @realDonaldTrump Trump nev...</td>\n",
              "      <td>['COVID19']</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ethel mertz</td>\n",
              "      <td>Stuck in the Middle</td>\n",
              "      <td>#Browns #Indians #ClevelandProud #[]_[] #Cavs ...</td>\n",
              "      <td>2019-03-07 01:45:06</td>\n",
              "      <td>197</td>\n",
              "      <td>987</td>\n",
              "      <td>1488</td>\n",
              "      <td>False</td>\n",
              "      <td>2020-07-25 12:27:10</td>\n",
              "      <td>@brookbanktv The one gift #COVID19 has give me...</td>\n",
              "      <td>['COVID19']</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DIPR-J&amp;K</td>\n",
              "      <td>Jammu and Kashmir</td>\n",
              "      <td>🖊️Official Twitter handle of Department of Inf...</td>\n",
              "      <td>2017-02-12 06:45:15</td>\n",
              "      <td>101009</td>\n",
              "      <td>168</td>\n",
              "      <td>101</td>\n",
              "      <td>False</td>\n",
              "      <td>2020-07-25 12:27:08</td>\n",
              "      <td>25 July : Media Bulletin on Novel #CoronaVirus...</td>\n",
              "      <td>['CoronaVirusUpdates', 'COVID19']</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-950cf813-1af8-4078-92ce-c36b9cb009ef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-950cf813-1af8-4078-92ce-c36b9cb009ef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-950cf813-1af8-4078-92ce-c36b9cb009ef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         user_name         user_location  ...               source is_retweet\n",
              "0           ᏉᎥ☻լꂅϮ            astroworld  ...   Twitter for iPhone      False\n",
              "1    Tom Basile 🇺🇸          New York, NY  ...  Twitter for Android      False\n",
              "2  Time4fisticuffs      Pewee Valley, KY  ...  Twitter for Android      False\n",
              "3      ethel mertz  Stuck in the Middle   ...   Twitter for iPhone      False\n",
              "4         DIPR-J&K     Jammu and Kashmir  ...  Twitter for Android      False\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets = pd.read_csv('data/covid_tweets.csv')\n",
        "tweets.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HV32GK6Da0Bj"
      },
      "outputs": [],
      "source": [
        "column = ['user_name','user_location','user_description','user_created','user_followers','hashtags', 'user_favourites','user_verified','is_retweet', 'source', 'user_friends']\n",
        "\n",
        "tweets.drop(columns=column, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Dropped irrelevant columns because the only data I want from the twitter datasets is text data and the date so I can join them by the same week number later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MR0O0uyCKqx"
      },
      "outputs": [],
      "source": [
        "tweets['date'] = pd.DatetimeIndex(tweets['date']).normalize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7LVFXTwDXqz"
      },
      "outputs": [],
      "source": [
        "tweets = tweets.groupby(['text', pd.Grouper(key='date', freq='W-SUN')]).sum().reset_index().sort_values('date')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4e79FTgbulNP",
        "outputId": "66d8d317-fcbe-414c-8c6f-69a807c3feb9"
      },
      "outputs": [],
      "source": [
        "#!pip install texthero"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Texthero is a python package to work with text data efficiently.\n",
        "It empowers NLP developers with a tool to quickly understand any text-based dataset and\n",
        "it provides a solid pipeline to clean and represent text data, from zero to hero.\n",
        "\n",
        "> Texthero was found doing self research, it helps quickly and effectively clean up text data so you can perform vectorization on it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9cIRSNs_vpa",
        "outputId": "ad6e6ff4-e6b3-4874-f7ca-1683088c7480"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import texthero as hero\n",
        "\n",
        "tweets['text'] = hero.clean(tweets['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dn6JUKwNaop0",
        "outputId": "ab859575-a79e-475a-ae33-eaa2f8e59636"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11020 entries, 0 to 11019\n",
            "Data columns (total 16 columns):\n",
            " #   Column            Non-Null Count  Dtype \n",
            "---  ------            --------------  ----- \n",
            " 0   id                11020 non-null  int64 \n",
            " 1   user_name         11020 non-null  object\n",
            " 2   user_location     8750 non-null   object\n",
            " 3   user_description  10341 non-null  object\n",
            " 4   user_created      11020 non-null  object\n",
            " 5   user_followers    11020 non-null  int64 \n",
            " 6   user_friends      11020 non-null  int64 \n",
            " 7   user_favourites   11020 non-null  int64 \n",
            " 8   user_verified     11020 non-null  bool  \n",
            " 9   date              11020 non-null  object\n",
            " 10  text              11020 non-null  object\n",
            " 11  hashtags          8438 non-null   object\n",
            " 12  source            11019 non-null  object\n",
            " 13  retweets          11020 non-null  int64 \n",
            " 14  favorites         11020 non-null  int64 \n",
            " 15  is_retweet        11020 non-null  bool  \n",
            "dtypes: bool(2), int64(6), object(8)\n",
            "memory usage: 1.2+ MB\n"
          ]
        }
      ],
      "source": [
        "vax_tw = pd.read_csv('data/vaccination_tweets.csv')\n",
        "vax_tw.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fno-em_C31NG"
      },
      "outputs": [],
      "source": [
        "cols = ['id','user_name','user_location','user_description','user_created','user_followers','user_favourites',\n",
        "'user_verified','hashtags','source','retweets','favorites','is_retweet', 'user_friends']\n",
        "\n",
        "vax_tw.drop(columns=cols, inplace=True)\n",
        "\n",
        "vax_tw['date'] = pd.DatetimeIndex(vax_tw['date']).normalize()\n",
        "\n",
        "vax_tw = vax_tw.groupby(['text', pd.Grouper(key='date', freq='W-SUN')]).sum().reset_index().sort_values('date')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D296TiYu06ib",
        "outputId": "01129e7a-9157-452b-f67a-f8757ff2f677"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 11014 entries, 7007 to 1927\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype         \n",
            "---  ------  --------------  -----         \n",
            " 0   text    11014 non-null  object        \n",
            " 1   date    11014 non-null  datetime64[ns]\n",
            "dtypes: datetime64[ns](1), object(1)\n",
            "memory usage: 258.1+ KB\n"
          ]
        }
      ],
      "source": [
        "vax_tw['text'] = hero.clean(vax_tw['text'])\n",
        "\n",
        "vax_tw.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Here I combined two different Twitter datasets. Both datasets are mostly about covid-19 and vaccinations. I pulled from relevant subjects because I believed that they would be the most correlated with predicting a pandemic. There are some normal tweets imbedded within that serves as an almost baseline.\n",
        "\n",
        "> To review, My data came from multiple sources, First I started with a base, almost cleaned, Kaggle dataset that had about 170k rows of tweets, for the sake of time and computational effectiveness, I trimmed down the dataset so I had more time for model tuning and other aspects of the project. I also gathered another 11k rows of tweets that were about vaccinations. Those two datasets were both used to create text based predictors using a CountVectorizer, to see if there was any direct correlation between the tweets and my target variable.\n",
        "\n",
        ">The target variable was constructed with both data from Google and the CDC. I created a score using the percentages of new cases as well as the relevance of searches. I then scaled the score down so outliers did not effect them as much. This accounts for not only physical outbreaks, but the social aspect as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jmmqokb_wJ-"
      },
      "source": [
        "## Combining Dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQBic02f_ylg"
      },
      "outputs": [],
      "source": [
        "tweet = tweets.sample(frac=0.5)\n",
        "\n",
        "df = [tweet, google, vax_tw]\n",
        "\n",
        "tash = tweet.merge(google, how='inner', on='date')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYl81HD34bMo"
      },
      "outputs": [],
      "source": [
        "from functools import reduce\n",
        "\n",
        "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['date'],\n",
        "                                            how='outer'), df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYHomsO4J75W"
      },
      "outputs": [],
      "source": [
        "df_merged['text_x'].fillna(df_merged['text_y'], inplace=True)\n",
        "\n",
        "df_merged.drop(columns='text_y', inplace=True)\n",
        "\n",
        "df_merged.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_merged.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> After joining together all of my dataframes, I realized there was a major problem, the only join that was functional was an outer join. When I attempted an inner join on the date columns they were deleting the values within and leaving only column names. To combat this I did an outer join with my dataframes, but had to fraction my larger twitter dataframe due to computational effectiveness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgVsFENqa0Bj"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXApDOw4a0Bk"
      },
      "outputs": [],
      "source": [
        "def tokenize(tweet):\n",
        "    tknzr = TweetTokenizer(strip_handles=True, reduce_len=True, \n",
        "                           preserve_case=False)\n",
        "    return tknzr.tokenize(tweet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRH8b1m4a0Bk"
      },
      "outputs": [],
      "source": [
        "def classifiers(x_train, y_train):\n",
        "    nb  = MultinomialNB()\n",
        "    nb.fit(x_train, y_train)\n",
        "    log = LogisticRegression()\n",
        "    log.fit(x_train, y_train)\n",
        "    forest = RandomForestClassifier(n_estimators=100, max_depth=5)\n",
        "    forest.fit(x_train, y_train)\n",
        "    gradboost = GradientBoostingClassifier(random_state=123, max_depth=5, \n",
        "                                          learning_rate = 0.01)\n",
        "    gradboost.fit(x_train, y_train)\n",
        "    adaboost = AdaBoostClassifier(n_estimators=100)\n",
        "    adaboost.fit(x_train, y_train)\n",
        "    svm = SVC(kernel='linear', probability=True)\n",
        "    svm.fit(x_train, y_train)\n",
        "    return [nb, log, forest, gradboost, adaboost, svm]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEh59cxpa0Bk"
      },
      "outputs": [],
      "source": [
        "def classifier_performance(vectorizer, train_data, test_data, y_test):\n",
        "    accuracy_df = []\n",
        "    x_train = vectorizer.fit_transform(train_data)\n",
        "    x_test = vectorizer.transform(test_data)\n",
        "    \n",
        "    classifier_list = classifiers(x_train, y_train)\n",
        "    for i in classifier_list:\n",
        "        preds = i.predict(x_test)\n",
        "        accuracy = accuracy_score(y_test, preds)\n",
        "  \n",
        "    accuracy_df = pd.DataFrame(accuracy_df)\n",
        "    classifiers_key = ['Naive Bayes', 'Random Forest', 'Gradient Boost',\n",
        "                      'AdaBoost', 'Support Vector Machine']\n",
        "    accuracy_df['Model'] = classifiers_key\n",
        "    accuracy_df.rename(columns={0: 'Accuracy'}, inplace=True)\n",
        "    fin_accuracy_df = accuracy_df[['Model', 'Accuracy']]\n",
        "    return fin_accuracy_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMTy0Fxua0Bl"
      },
      "outputs": [],
      "source": [
        "def model_performance(model, vectorizer):\n",
        "  \n",
        "    train_data = vectorizer.fit_transform(x_train)\n",
        "    test_data = vectorizer.transform(x_test)\n",
        "\n",
        "    model.fit(train_data, y_train)\n",
        "\n",
        "    pred = model.predict(test_data)\n",
        "\n",
        "    return f'{model}', accuracy_score(y_test, pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6f8CYpmo7qla"
      },
      "outputs": [],
      "source": [
        "def griddy(model, params, vectorizer):\n",
        "  X_train = vectorizer.fit_transform(x_train)\n",
        "  X_test = vectorizer.transform(x_test)\n",
        "\n",
        "  grid = GridSearchCV(estimator=model, param_grid=params, n_jobs=-1, cv=6)\n",
        "  grid.fit(X_train, y_train)\n",
        "\n",
        "  return [grid.best_params_, grid.accuracy_score, grid.recall_score]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx4K6WxVa0Bl"
      },
      "source": [
        "## Count Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> In this next section I created baseline models to run through my data on different vectorizations. I used a Count Vectorizer and TFIDF Vectorizer with different n-grams to test the potential of the models.\n",
        "\n",
        ">After taking an iterative modeling approach, I found that one model performed exceptionally better than other models. Using the Multinomial Naive Bayes model I was able to predict outbreaks at a 40 percent accuracy. Part of the reason the Naive Bayes worked better than other models is because it assumes independence between my variables, meaning each of them is counted on its own without any weights, this pairs well with a CountVectorizer because it establishes importance based on word count."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTU-1wf78t4h"
      },
      "outputs": [],
      "source": [
        "data = df_merged['text_x']\n",
        "labels = df_merged['relevance']\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, labels)\n",
        "tfidfvec = TfidfVectorizer(stop_words='english', tokenizer=tokenize)\n",
        "tfidfvec2 = TfidfVectorizer(stop_words='english', tokenizer=tokenize, ngram_range=(1,2))\n",
        "tfidfvec3 = TfidfVectorizer(stop_words='english', tokenizer=tokenize, ngram_range=(1,3))\n",
        "countvec = CountVectorizer(stop_words='english', tokenizer=tokenize)\n",
        "countvec2 = CountVectorizer(stop_words='english', tokenizer=tokenize, ngram_range=(1,2))\n",
        "countvec3 = CountVectorizer(stop_words='english', tokenizer=tokenize, ngram_range=(1,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmSocC27R3b_"
      },
      "outputs": [],
      "source": [
        "nb  = MultinomialNB()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PS-01yt19pj",
        "outputId": "47c9d824-dbe3-4d86-efe6-5e45bf2756ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('MultinomialNB()', 0.29124860646599776)"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_performance(nb, countvec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cr5-ZhxGu92v"
      },
      "outputs": [],
      "source": [
        "forest = RandomForestClassifier(n_estimators=100, max_depth=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wE2KXHe0fyOP"
      },
      "outputs": [],
      "source": [
        "model_performance(forest, countvec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrGyXiyju98K"
      },
      "outputs": [],
      "source": [
        "#gradboost = GradientBoostingClassifier(random_state=123, max_depth=5, learning_rate = 0.01)\n",
        "#model_performance(gradboost, countvec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnLpmFIFu-BM"
      },
      "outputs": [],
      "source": [
        "#adaboost = AdaBoostClassifier(n_estimators=100)\n",
        "#model_performance(adaboost, countvec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvdMLdUfa0Bm"
      },
      "source": [
        "### Bigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ri8YnrVa0Bm"
      },
      "outputs": [],
      "source": [
        "model_performance(nb, countvec2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czSDiOWT3k6T"
      },
      "outputs": [],
      "source": [
        "model_performance(forest, countvec2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czQYj0c93lBx"
      },
      "outputs": [],
      "source": [
        "#model_performance(gradboost, countvec2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZsTaHfF3lMT"
      },
      "outputs": [],
      "source": [
        "#model_performance(adaboost, countvec2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kTOUGWda0Bm"
      },
      "source": [
        "### Trigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVgmIXofa0Bm"
      },
      "outputs": [],
      "source": [
        "model_performance(nb, countvec3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1YgXQQ03x_N"
      },
      "outputs": [],
      "source": [
        "model_performance(forest, countvec3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOSS-7cZ3yFp"
      },
      "outputs": [],
      "source": [
        "#model_performance(gradboost, countvec3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWgoklSk3yMf"
      },
      "outputs": [],
      "source": [
        "#model_performance(adaboost, countvec3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXez9pPaa0Bm"
      },
      "source": [
        "## TF-IDF Vectorization\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Z0DUnDda0Bn"
      },
      "source": [
        "### Unigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAKhkWk3Uhqe"
      },
      "outputs": [],
      "source": [
        "model_performance(nb, tfidfvec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qanvks1zUhue"
      },
      "outputs": [],
      "source": [
        "model_performance(forest, tfidfvec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hx4Elwc5Uhze"
      },
      "outputs": [],
      "source": [
        "#model_performance(gradboost, tfidfvec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJS4k3wxUh4I"
      },
      "outputs": [],
      "source": [
        "#model_performance(adaboost, tfidfvec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuGffLnha0Bn"
      },
      "source": [
        "### Bigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJgW9JVS4E7q"
      },
      "outputs": [],
      "source": [
        "model_performance(nb, tfidfvec2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uGhWM_K4P4l"
      },
      "outputs": [],
      "source": [
        "model_performance(forest, tfidfvec2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8FniHEa4P6U"
      },
      "outputs": [],
      "source": [
        "#model_performance(gradboost, tfidfvec2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdLIz0TR4P81"
      },
      "outputs": [],
      "source": [
        "#model_performance(adaboost, tfidfvec2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIxEfvO-Ub7a"
      },
      "source": [
        "### Trigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1KlB60s04EUf"
      },
      "outputs": [],
      "source": [
        "model_performance(nb, tfidfvec3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMS23Xza4XA2"
      },
      "outputs": [],
      "source": [
        "model_performance(forest, tfidfvec3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3meCIsau4XFI"
      },
      "outputs": [],
      "source": [
        "#model_performance(gradboost, tfidfvec3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_03dJRH4XNG"
      },
      "outputs": [],
      "source": [
        "#model_performance(adaboost, tfidfvec3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUPSnVSO-Dgo"
      },
      "source": [
        "\n",
        "## Improving models\n",
        "\n",
        "> Trying to improve the best performing models from the previous cells, The two best performing were Random Forests and Naive Bayes, So running grid searches on them to see if there is any hyperparameter tuning that I could do to further improve the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4C8gz-qG-Guz",
        "outputId": "75b254c2-1b48-436f-9993-a2d957012ade"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:705: UserWarning:\n",
            "\n",
            "A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=6, estimator=MultinomialNB(), n_jobs=-1,\n",
              "             param_grid={'alpha': [1, 5, 10, 50, 100]}, scoring='accuracy')"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train = countvec3.fit_transform(x_train)\n",
        "X_test = countvec3.transform(x_test)\n",
        "\n",
        "param_grid = {'alpha': [1, 5, 10, 50, 100]}\n",
        "\n",
        "clf = GridSearchCV(estimator=nb, param_grid=param_grid, n_jobs=-1, cv=6, scoring='accuracy')\n",
        "clf.fit(X_train, y_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9HZwz8NEiTU"
      },
      "outputs": [],
      "source": [
        "clf.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "j6qfF52vd0p8",
        "outputId": "309a457e-b9c7-485d-c0c3-0c000ea97dcf"
      },
      "outputs": [],
      "source": [
        "#params = {'criterion' : ['gini', 'entropy'],\n",
        "          #'max_depth' : [3, 4, 5, 6, 7, 8],\n",
        "          #'min_samples_split' : [2, 4, 6, 8, 10],\n",
        "          #'min_samples_leaf' : [1, 2, 3, 4, 5],\n",
        "          #'n_estimators' : [10, 25, 50, 100, 150, 200],\n",
        "          #'bootstrap' : [True, False]}\n",
        "\n",
        "#griddy(forest, params, countvec3)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Ir9A43poUdbB",
        "ZX2rpTgka0Be",
        "FV3-1UKAa0Bg",
        "5jmmqokb_wJ-"
      ],
      "include_colab_link": true,
      "name": "Copy of Pre-processing.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "420e256bc500c12e3806917528f8011d4c65966182bb00d6f8bbf9f6d2442e0d"
    },
    "kernelspec": {
      "display_name": "Python (learn-env)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
